import numpy as np
import pandas as pd
from keras.models import Sequential
from keras.layers import Dense, Dropout
from sklearn.preprocessing import StandardScaler

# set random seed for reproducibility
np.random.seed(1)

# load dataset
df = pd.read_csv('data.csv')

# create time series features
df['year'] = pd.to_datetime(df['date']).dt.year
df['month'] = pd.to_datetime(df['date']).dt.month
df['day'] = pd.to_datetime(df['date']).dt.day

# split dataset into train and test sets
train_size = int(len(df) * 0.8)
train_data, test_data = df.iloc[0:train_size], df.iloc[train_size:len(df)]

# prepare input and output variables
scaler = StandardScaler()
train_X, train_y = train_data[['feature1', 'feature2', 'year', 'month', 'day']].values, train_data['target'].values
train_X = scaler.fit_transform(train_X)
test_X, test_y = test_data[['feature1', 'feature2', 'year', 'month', 'day']].values, test_data['target'].values
test_X = scaler.transform(test_X)

# set hyperparameters
batch_size = 32
epochs = 100
learning_rate = 0.001
dropout_rate = 0.2

# define MLP model
model = Sequential()
model.add(Dense(50, input_dim=train_X.shape[1], activation='relu'))
model.add(Dropout(dropout_rate))
model.add(Dense(25, activation='relu'))
model.add(Dropout(dropout_rate))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')

# train MLP model
model.fit(train_X, train_y, batch_size=batch_size, epochs=epochs, verbose=1)

# evaluate MLP model on test set
mse = model.evaluate(test_X, test_y, verbose=0)
print('Mean Squared Error: {:.2f}'.format(mse))






##### LSTM
import numpy as np
import pandas as pd
from keras.models import Sequential
from keras.layers import LSTM, Dense

# load dataset
df = pd.read_csv('data.csv')

# create time series features
df['year'] = pd.to_datetime(df['date']).dt.year
df['month'] = pd.to_datetime(df['date']).dt.month
df['day'] = pd.to_datetime(df['date']).dt.day

# split dataset into train and test sets
train_size = int(len(df) * 0.8)
train_data, test_data = df.iloc[0:train_size], df.iloc[train_size:len(df)]

# prepare input and output variables
train_X, train_y = train_data[['feature1', 'feature2', 'year', 'month', 'day']].values, train_data['target'].values
test_X, test_y = test_data[['feature1', 'feature2', 'year', 'month', 'day']].values, test_data['target'].values

# reshape input to be 3D [samples, timesteps, features]
n_features = train_X.shape[1]
train_X = train_X.reshape((train_X.shape[0], 1, n_features))
test_X = test_X.reshape((test_X.shape[0], 1, n_features))

# create LSTM model
model = Sequential()
model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))
model.add(Dense(1))
model.compile(loss='mse', optimizer='adam')

# fit model
model.fit(train_X, train_y, epochs=50, batch_size=32, validation_data=(test_X, test_y), verbose=2, shuffle=False)

# make predictions
predictions = model.predict(test_X)

# evaluate model
mse = mean_squared_error(test_y, predictions)
print('Mean Squared Error: %.3f' % mse)


#####XGB
import numpy as np
import pandas as pd
import xgboost as xgb
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error

# set random seed for reproducibility
np.random.seed(1)

# load dataset
df = pd.read_csv('data.csv')

# create time series features
df['year'] = pd.to_datetime(df['date']).dt.year
df['month'] = pd.to_datetime(df['date']).dt.month
df['day'] = pd.to_datetime(df['date']).dt.day

# split dataset into train and test sets
train_size = int(len(df) * 0.8)
train_data, test_data = df.iloc[0:train_size], df.iloc[train_size:len(df)]

# prepare input and output variables
scaler = StandardScaler()
train_X, train_y = train_data[['feature1', 'feature2', 'year', 'month', 'day']].values, train_data['target'].values
train_X = scaler.fit_transform(train_X)
test_X, test_y = test_data[['feature1', 'feature2', 'year', 'month', 'day']].values, test_data['target'].values
test_X = scaler.transform(test_X)

# set hyperparameters
params = {
    'n_estimators': 100,
    'max_depth': 5,
    'learning_rate': 0.1,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    'objective': 'reg:squarederror',
    'seed': 1
}

# train XGBoost model
model = xgb.XGBRegressor(**params)
model.fit(train_X, train_y)

# make predictions on test set
y_pred = model.predict(test_X)

# evaluate XGBoost model on test set
mse = mean_squared_error(test_y, y_pred)
print('Mean Squared Error: {:.2f}'.format(mse))


##### prophet
import pandas as pd
from fbprophet import Prophet

# load dataset
df = pd.read_csv('data.csv')

# create time series features
df['ds'] = pd.to_datetime(df['date'])
df['year'] = pd.to_datetime(df['date']).dt.year
df['month'] = pd.to_datetime(df['date']).dt.month
df['day'] = pd.to_datetime(df['date']).dt.day

# split dataset into train and test sets
train_size = int(len(df) * 0.8)
train_data, test_data = df.iloc[0:train_size], df.iloc[train_size:len(df)]

# prepare input and output variables
train_data = train_data.rename(columns={'target': 'y'})
train_data = train_data[['ds', 'y', 'feature1', 'feature2', 'year', 'month', 'day']]
test_data = test_data.rename(columns={'target': 'y'})
test_data = test_data[['ds', 'y', 'feature1', 'feature2', 'year', 'month', 'day']]

# create Prophet model with external regressors
model = Prophet(seasonality_mode='additive')
model.add_regressor('feature1')
model.add_regressor('feature2')
model.add_regressor('year')
model.add_regressor('month')
model.add_regressor('day')

# fit Prophet model on training data
model.fit(train_data)

# make predictions on test data
future_data = model.make_future_dataframe(periods=len(test_data))
future_data['feature1'] = test_data['feature1'].values
future_data['feature2'] = test_data['feature2'].values
future_data['year'] = test_data['year'].values
future_data['month'] = test_data['month'].values
future_data['day'] = test_data['day'].values
forecast_data = model.predict(future_data)

# evaluate Prophet model on test data
mse = ((forecast_data.iloc[train_size:, -1] - test_data['y']) ** 2).mean()
print('Mean Squared Error: {:.2f}'.format(mse))
